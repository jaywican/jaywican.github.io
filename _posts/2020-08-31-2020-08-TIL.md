---
layout: post
title: 2020.08 TIL
comments: true
tags : [TIL, CNN, NLP]
---

# 20.08.03

## word2vec

> <https://wikidocs.net/22660>

- 단어를 벡터로 맵핑하는 과정에서, 원핫인코딩과 같은 sparse representation(희소 표현) 말고, distributed representation(분산 표현)을 하기 위한 방식.

- 단어의 '의미'를 다차원 공간에 벡터화 시킬 수 있으므로, 유사도 표현 가능.

- **CBOW(Continuous Bag of Words)**

  - 주변부 단어들로부터 중간 단어 예측

  - 중간 단어 기준 앞 뒤로 몇개의 단어 볼지? -> 윈도우(window)

  - 학습 데이터 : 문장을 sliding window로 지나가며, input, label을 원핫벡터로 구성

  - 학습 모델 : Input layer - (W)-> hidden layer 1개(=projection layer) -(W')-> output layer

    - projection layer 로 갈 때 벡터의 평균 구함

  - 임베딩 벡터 룩업테이블 : weight matrix W or W'

- **Skip-Gram**

  - 중간 단어로부터 주변부 단어들 예측
  - 학습 모델 : Input layer - (W)-> hidden layer 1개(=projection layer) -(W')-> output layer
    - projection layer 로 갈 때 평균 구하지 않음
  - cbow 보다 skip-gram 이 성능 더 좋다고 알려짐

- 단점
  - 미등록단어 처리 어려움

## FastText

> <https://brunch.co.kr/@learning/7>

- 2016년 facebook에서 발표
- 원래 단어를 subword(부분단어)의 벡터들로 표현함.
  - 텍스트의 최소 단위 : 단어를 구성하는 글자 n-gram
  - 단어를 구성하는 모든 n-gram 벡터의 평균 벡터를 임베딩

***

# 20.08.12

## CNN Visualization

> <https://fabj.tistory.com/56>
>
> <https://zzsza.github.io/data/2018/06/04/cs231n-visualizing-and-understanding/>

- ### CAM(Class Activation Map)

  > <https://kangbk0120.github.io/articles/2018-02/cam>

  - 한번 해봤음
  - 클래스 별 활성화 부분 알 수 있음
  - CNN 모델의 마지막 FC 레이어를, GAP 레이어로 바꾼 후, 학습 시켜야함.

- ### Grad Cam

  > <https://www.secmem.org/blog/2020/01/17/gradcam/>

  - GAP 레이어 대신 gradient 이용하자
  - CNN 모델 구조 수정 하지 않아도 됨.
  - 관찰하려는 conv layer의 gradient

- Occlusion Map

  - input 이미지의 어떤 부분이 분류에 영향을 미치는지 알아보기

  - 이미지 일부를 마스크 씌운 후, 분류 스코어 측정

  - 특정 부분에 마스크를 씌웠을 때 분류 스코어가 떨어진다면, 그 부분은 중요할 것이다~

- ### Filter(=weight)

- ### Feature map

  > <https://pythonkim.tistory.com/163>

  - Filter를 거쳐서 나온 결과물(convolution layer, pooling layer)
  - feature map이 이미지는 아니지만, 이미지로 표시할 수 있는 데이터 범위로 스케일링 하면, 각각의 픽셀 상관관계를 볼 수 있음

## opencv2, PIL

- PIL 에서 4채널 이미지의 배경부분 흰색으로 만들기

  ```python
  img = Image.open(img_name).convert('RGBA')
  img_ = Image.new("RGBA", img.size, "WHITE") # white background
  img_.paste(img, (0, 0), img)
  ```

- cv2 <-> PIL

  > <https://stackoverflow.com/questions/43232813/convert-opencv-image-format-to-pil-image-format>

  ```python
  import cv2
  import numpy as np
  from PIL import Image
  
  img = cv2.imread("path/to/img.png")
  
  # You may need to convert the color.
  img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
  im_pil = Image.fromarray(img)
  
  # For reversing the operation:
  im_np = np.asarray(im_pil)
  ```

  - cv2 는 RGB 순서로 읽어오는게 아니라, BGR 순서로 읽어옴.
  - 그런데 또 `cv2.imshow()` , `cv2.imwrite()` 로 보여주거나 저장할 때는 자동으로 잘 됨ㅎ
  - 하지만 `matplotlib` , `PIL` 에서 이미지 보여주려면 위와 같이 RGB로 바꾼 후 해야함

***

# 20.08.13

## pytorch

- forward hook 걸어서 특정 레이어의 output 추출

  ```python
  activation = {}
  def get_activation(name):
      def hook(model, input, output):
          activation[name] = output.detach()
      return hook

  model.layer_name.register_forward_hook(get_activation('layer_name'))
  model(input)
  
  # 훅 등록하고, model에 입력값 넣어서 순방향 네트워크 진행하면 자동으로 activation 딕셔너리에 값 들어감.
  # 단, batch로 할 때는 계속 바뀌니까, get_activation() 함수에 추가 작업 해줘야함.
  ```
